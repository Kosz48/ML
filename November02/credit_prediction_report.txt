Содержательно опишем задачу. Что мы предсказываем?

В этом проекте мы пытаемся предсказать, будет ли человек возвращать кредит или нет. Это важно для банков, чтобы решить, выдавать ли кредит и снизить риски невозврата денег.

Какой объем данных (N)? Сколько признаков (d)? Сколько классов (K)?

Объем данных (N): У нас есть данные о 32 581 человеке.
Количество признаков (d): После обработки у нас осталось 22 признака.
Количество классов (K): Два класса:
0 — человек вернул кредит вовремя.
1 — человек не вернул кредит (допустил дефолт).

Какие типы признаков?

У нас есть числовые и категориальные признаки:

Числовые признаки:
- Возраст
- Доход
- Стаж работы
- Сумма кредита
- Процентная ставка
- Доля кредита от дохода
- Длина кредитной истории

Категориальные признаки:
- Владение жильем (аренда, собственность и т.д.)
- Цель кредита (личные нужды, образование и т.д.)
- Кредитный рейтинг
- Были ли предыдущие дефолты

Были ли пропущенные значения?

Да, были пропущенные значения в некоторых признаках:
- Стаж работы ('person_emp_length'): 895 пропущенных значений.
- Процентная ставка ('loan_int_rate'): 3 116 пропущенных значений.
Мы заполнили пропуски медианными значениями этих признаков.

Сбалансированы ли классы?

Нет, классы несбалансированы:
- Класс 0 (вернул кредит): 25 473 записей.
- Класс 1 (не вернул кредит): 7 108 записей.
Чтобы исправить это, мы использовали метод SMOTE, который увеличил количество записей меньшего класса до баланса.

Диаграммы рассеивания и корреляционная матрица. Какие выводы?

- Гистограммы: Мы построили гистограммы числовых признаков и увидели, что некоторые из них имеют перекос или выбросы.
- Корреляционная матрица: Мы посмотрели на корреляцию между признаками. Сильно коррелированных признаков (с корреляцией больше 0.9) не обнаружили. Значит, мультиколлинеарность не является большой проблемой.

Какую делали предобработку?

- Обработка пропущенных значений: Заполнили пропуски медианными значениями.
- Кодирование категориальных признаков: Преобразовали категориальные признаки в числовые с помощью One-Hot Encoding.
- Нормализация данных: Нормализовали числовые признаки, чтобы привести их к одному масштабу.
- Балансировка классов: Использовали SMOTE для уравновешивания классов.

Какой метод оказался лучшим? Какая ошибка?

- Лучше всего сработал Случайный лес:
  - Точность на тестовых данных: 93.01%
  - Ошибка на тестовых данных: 6.99% (100% - 93.01%)

Какой метод оказался худшим? Какая ошибка?

- Хуже всего показала себя Логистическая регрессия:
  - Точность на тестовых данных: 86.49%
  - Ошибка на тестовых данных: 13.51% (100% - 86.49%)

Помог ли PCA?

Мы попробовали метод PCA для уменьшения количества признаков:
- Количество признаков уменьшилось: с 22 до 13.
- Точность модели после PCA: 88.51%
- Точность немного снизилась, поэтому в нашем случае PCA не улучшил результат.

Вывод:

Мы провели анализ данных и применили разные модели. Случайный лес показал лучший результат в предсказании того, вернет ли человек кредит. Предобработка данных и балансировка классов помогли улучшить качество модели. Использование PCA в нашем случае не дало улучшения.
